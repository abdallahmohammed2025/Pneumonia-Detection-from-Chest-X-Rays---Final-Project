{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Pneumonia Detection from Chest X-Rays\n",
       "\n",
       "## Deliverable 1: Deep Learning Project Notebook\n",
       "\n",
       "This notebook demonstrates a CNN-based pneumonia detection system from chest X-ray images, including exploratory data analysis (EDA), model building and training, Grad-CAM visualization for explainability, and evaluation."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Install kagglehub if not installed\n",
       "# !pip install kagglehub\n",
       "\n",
       "import kagglehub\n",
       "import os\n",
       "import zipfile\n",
       "\n",
       "# Download latest version of the dataset\n",
       "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
       "print(\"Path to dataset files:\", path)\n",
       "\n",
       "# Extract zip archive\n",
       "dataset_zip = path\n",
       "dataset_dir = \"./chest_xray_pneumonia\"\n",
       "\n",
       "with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
       "    zip_ref.extractall(dataset_dir)\n",
       "\n",
       "print(\"Dataset extracted to:\", dataset_dir)\n",
       "\n",
       "# Define train and test directories\n",
       "train_dir = os.path.join(dataset_dir, 'chest_xray', 'train')\n",
       "test_dir = os.path.join(dataset_dir, 'chest_xray', 'test')\n",
       "\n",
       "print(\"Train directory:\", train_dir)\n",
       "print(\"Test directory:\", test_dir)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Exploratory Data Analysis (EDA)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import matplotlib.pyplot as plt\n",
       "from matplotlib.image import imread\n",
       "import numpy as np\n",
       "import os\n",
       "\n",
       "# Count images in train dataset\n",
       "train_normal = os.listdir(os.path.join(train_dir, 'NORMAL'))\n",
       "train_pneumonia = os.listdir(os.path.join(train_dir, 'PNEUMONIA'))\n",
       "\n",
       "print(f\"Number of training NORMAL images: {len(train_normal)}\")\n",
       "print(f\"Number of training PNEUMONIA images: {len(train_pneumonia)}\")\n",
       "\n",
       "# Visualize some example images\n",
       "def plot_sample_images(folder, label, n=5):\n",
       "    plt.figure(figsize=(15,5))\n",
       "    for i, img_name in enumerate(folder[:n]):\n",
       "        img = imread(os.path.join(label, img_name))\n",
       "        plt.subplot(1, n, i+1)\n",
       "        plt.imshow(img, cmap='gray')\n",
       "        plt.title(label.split(os.sep)[-1])\n",
       "        plt.axis('off')\n",
       "    plt.show()\n",
       "\n",
       "plot_sample_images(train_normal, os.path.join(train_dir, 'NORMAL'))\n",
       "plot_sample_images(train_pneumonia, os.path.join(train_dir, 'PNEUMONIA'))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Data Preprocessing and Loading"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
       "\n",
       "# Image parameters\n",
       "img_height, img_width = 150, 150\n",
       "batch_size = 32\n",
       "\n",
       "# Data augmentation and preprocessing\n",
       "train_datagen = ImageDataGenerator(\n",
       "    rescale=1./255,\n",
       "    shear_range=0.2,\n",
       "    zoom_range=0.2,\n",
       "    horizontal_flip=True)\n",
       "\n",
       "test_datagen = ImageDataGenerator(rescale=1./255)\n",
       "\n",
       "# Load images from directories\n",
       "train_generator = train_datagen.flow_from_directory(\n",
       "    train_dir,\n",
       "    target_size=(img_height, img_width),\n",
       "    batch_size=batch_size,\n",
       "    class_mode='binary')\n",
       "\n",
       "test_generator = test_datagen.flow_from_directory(\n",
       "    test_dir,\n",
       "    target_size=(img_height, img_width),\n",
       "    batch_size=batch_size,\n",
       "    class_mode='binary',\n",
       "    shuffle=False)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Model Architecture (CNN)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import tensorflow as tf\n",
       "from tensorflow.keras.models import Sequential\n",
       "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
       "\n",
       "model = Sequential([\n",
       "    Conv2D(32, (3,3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
       "    MaxPooling2D(2,2),\n",
       "    Conv2D(64, (3,3), activation='relu'),\n",
       "    MaxPooling2D(2,2),\n",
       "    Conv2D(128, (3,3), activation='relu'),\n",
       "    MaxPooling2D(2,2),\n",
       "    Flatten(),\n",
       "    Dense(128, activation='relu'),\n",
       "    Dropout(0.5),\n",
       "    Dense(1, activation='sigmoid')\n",
       "])\n",
       "\n",
       "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
       "\n",
       "model.summary()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Model Training"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "epochs = 10\n",
       "\n",
       "history = model.fit(\n",
       "    train_generator,\n",
       "    epochs=epochs,\n",
       "    validation_data=test_generator\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Plot Training History"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "plt.figure(figsize=(12,5))\n",
       "\n",
       "plt.subplot(1,2,1)\n",
       "plt.plot(history.history['loss'], label='train loss')\n",
       "plt.plot(history.history['val_loss'], label='val loss')\n",
       "plt.legend()\n",
       "plt.title('Loss')\n",
       "\n",
       "plt.subplot(1,2,2)\n",
       "plt.plot(history.history['accuracy'], label='train accuracy')\n",
       "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
       "plt.legend()\n",
       "plt.title('Accuracy')\n",
       "\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Model Evaluation on Test Set"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "loss, accuracy = model.evaluate(test_generator)\n",
       "print(f\"Test loss: {loss:.4f}\")\n",
       "print(f\"Test accuracy: {accuracy:.4f}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 7. Grad-CAM Visualization for Explainability"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import tensorflow.keras.backend as K\n",
       "import cv2\n",
       "import numpy as np\n",
       "\n",
       "def get_img_array(img_path, size):\n",
       "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
       "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
       "    array = np.expand_dims(array, axis=0)\n",
       "    array /= 255.0\n",
       "    return array\n",
       "\n",
       "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
       "    grad_model = tf.keras.models.Model(\n",
       "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
       "\n",
       "    with tf.GradientTape() as tape:\n",
       "        conv_outputs, predictions = grad_model(img_array)\n",
       "        if pred_index is None:\n",
       "            pred_index = tf.argmax(predictions[0])\n",
       "        class_channel = predictions[:, pred_index]\n",
       "\n",
       "    grads = tape.gradient(class_channel, conv_outputs)\n",
       "\n",
       "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
       "\n",
       "    conv_outputs = conv_outputs[0]\n",
       "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
       "    heatmap = tf.squeeze(heatmap)\n",
       "\n",
       "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
       "    return heatmap.numpy()\n",
       "\n",
       "import matplotlib.cm as cm\n",
       "\n",
       "# Select last convolutional layer name\n",
       "last_conv_layer_name = 'conv2d_2'  # Based on model.summary()\n",
       "\n",
       "# Pick sample images for visualization\n",
       "sample_normal_img = os.path.join(train_dir, 'NORMAL', train_normal[0])\n",
       "sample_pneumonia_img = os.path.join(train_dir, 'PNEUMONIA', train_pneumonia[0])\n",
       "\n",
       "for img_path, label in [(sample_normal_img, 'Normal'), (sample_pneumonia_img, 'Pneumonia')]:\n",
       "    img_array = get_img_array(img_path, size=(img_height, img_width))\n",
       "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
       "\n",
       "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
       "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
       "    img = cv2.resize(img, (img_width, img_height))\n",
       "\n",
       "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
       "    heatmap = np.uint8(255 * heatmap)\n",
       "\n",
       "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
       "\n",
       "    superimposed_img = heatmap * 0.4 + img\n",
       "    superimposed_img = np.uint8(superimposed_img)\n",
       "\n",
       "    plt.figure(figsize=(8,8))\n",
       "    plt.title(f\"Grad-CAM: {label}\")\n",
       "    plt.axis('off')\n",
       "    plt.imshow(superimposed_img)\n",
       "    plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 8. Conclusion\n",
       "\n",
       "This notebook demonstrated a CNN model to detect pneumonia from chest X-rays with good accuracy. The Grad-CAM visualizations provide insight into regions of the X-ray images influencing the model's predictions, increasing explainability.\n",
       "\n",
       "Further improvements may include experimenting with transfer learning, hyperparameter tuning, or using ensemble models."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   