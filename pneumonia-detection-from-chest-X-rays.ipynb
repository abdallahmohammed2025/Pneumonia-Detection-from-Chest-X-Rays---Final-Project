{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df7fe962",
   "metadata": {},
   "source": [
    "# Pneumonia Detection from Chest X-Rays using CNN + Grad-CAM\n",
    "\n",
    "This notebook is part of a deep learning final project. The goal is to detect pneumonia in chest X-ray images using convolutional neural networks (CNNs) and interpret the predictions using Grad-CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ce22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33658147",
   "metadata": {},
   "source": [
    "## 1. Problem Description\n",
    "Pneumonia is a serious lung infection that requires timely diagnosis. Chest X-rays are commonly used, but interpreting them can be challenging. Deep learning provides a scalable and effective solution for automatic pneumonia detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d712d07",
   "metadata": {},
   "source": [
    "## 2. Data Loading and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct path to dataset\n",
    "data_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray'\n",
    "\n",
    "# Define dataset subset paths\n",
    "train_path = os.path.join(data_dir, 'train')\n",
    "val_path = os.path.join(data_dir, 'val')\n",
    "test_path = os.path.join(data_dir, 'test')\n",
    "\n",
    "# Print dataset distribution\n",
    "for subset in ['train', 'val', 'test']:\n",
    "    normal_path = os.path.join(data_dir, subset, 'NORMAL')\n",
    "    pneumonia_path = os.path.join(data_dir, subset, 'PNEUMONIA')\n",
    "    \n",
    "    if os.path.isdir(normal_path) and os.path.isdir(pneumonia_path):\n",
    "        normal = len(os.listdir(normal_path))\n",
    "        pneumonia = len(os.listdir(pneumonia_path))\n",
    "        print(f'{subset.upper()} - NORMAL: {normal}, PNEUMONIA: {pneumonia}')\n",
    "    else:\n",
    "        print(f'{subset.upper()} - One or both class folders not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c4ad0",
   "metadata": {},
   "source": [
    "### Sample Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380226f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train path\n",
    "train_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train'\n",
    "\n",
    "# Search for images with multiple possible extensions\n",
    "image_extensions = ['*.jpeg', '*.jpg', '*.png']\n",
    "image_files = []\n",
    "for ext in image_extensions:\n",
    "    image_files.extend(glob(os.path.join(train_path, 'PNEUMONIA', ext)))\n",
    "\n",
    "# Show image if found\n",
    "if image_files:\n",
    "    img_path = image_files[0]\n",
    "    img = cv2.imread(img_path)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Sample Pneumonia Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images found in PNEUMONIA folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b9c748",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2931ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (150, 150)\n",
    "train_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, horizontal_flip=True)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_gen.flow_from_directory(train_path, target_size=img_size, class_mode='binary')\n",
    "val_data = test_gen.flow_from_directory(val_path, target_size=img_size, class_mode='binary')\n",
    "test_data = test_gen.flow_from_directory(test_path, target_size=img_size, class_mode='binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac82f62",
   "metadata": {},
   "source": [
    "## 4. Model Building (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff83853",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaaa425",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "history = model.fit(train_data, validation_data=val_data, epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22784b3",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb230ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')\n",
    "loss, acc = model.evaluate(test_data)\n",
    "print(f'Test Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ae31d",
   "metadata": {},
   "source": [
    "## 7. Grad-CAM Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f6150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM helper functions\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # Get the last conv layer output\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    \n",
    "    # Create a new model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.layers[0].input,    # Use the first layer input instead of model.inputs\n",
    "        outputs=[last_conv_layer.output, model.layers[-1].output]  # Use last layer output\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    if img_path is not None and os.path.exists(img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        print(f\"Warning: Image path {img_path} not found.\")\n",
    "        return\n",
    "\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    jet = plt.cm.get_cmap(\"jet\")\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "    jet_heatmap = cv2.resize(jet_heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    superimposed_img = jet_heatmap * alpha + img / 255.0\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 1)  # Clip to valid range\n",
    "\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Find last conv layer in the model\n",
    "last_conv_layer_name = None\n",
    "for layer in reversed(model.layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        last_conv_layer_name = layer.name\n",
    "        break\n",
    "\n",
    "if last_conv_layer_name is None:\n",
    "    raise ValueError(\"No Conv2D layer found in the model.\")\n",
    "\n",
    "print(f\"Last conv layer: {last_conv_layer_name}\")\n",
    "\n",
    "# Run dummy input to build model (fixes AttributeError)\n",
    "dummy_input = tf.zeros((1, 150, 150, 3))\n",
    "_ = model(dummy_input)\n",
    "\n",
    "# Prepare test generator (adjust batch size accordingly)\n",
    "test_generator = test_gen.flow_from_directory(\n",
    "    test_path, target_size=img_size, class_mode='binary', shuffle=False, batch_size=5)\n",
    "\n",
    "test_images, test_labels = next(test_generator)\n",
    "test_filenames = test_generator.filenames[:len(test_images)]\n",
    "\n",
    "for i, img in enumerate(test_images):\n",
    "    img_array = np.expand_dims(img, axis=0)\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "\n",
    "    img_path = os.path.join(test_path, test_filenames[i])\n",
    "    save_and_display_gradcam(img_path, heatmap, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230fca2a",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "The CNN-based approach demonstrates high accuracy in detecting pneumonia. Grad-CAM visualization provides interpretability, which is critical for medical applications. Further improvements may include transfer learning with pre-trained models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
